{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T09:55:45.908708Z",
     "start_time": "2022-01-04T09:55:45.822917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /public/home/lizw/task/pore_c/tools/porecscripts/v2.15/porecplot_draw_func.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/public/home/lizw/task/pore_c/tools/porecscripts/v2.15/porecplot_draw_func.py' \n",
    "\n",
    "#@Author: Zhuowen Li\n",
    "#@LastEdit: 2022/1/4 下午5:30:48\n",
    "#@Version: \n",
    "#@Description: \n",
    "#line156: remove the max nomalization in contact interaction index calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mp\n",
    "from sys import exit\n",
    "import os\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "#calculating function\n",
    "\n",
    "def chr_interval(df,region,column,binsize):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    df_region_filter_merge = pd.DataFrame([])\n",
    "    chrinterval_all = pd.DataFrame([])\n",
    "    df_bins_dict = {}\n",
    "    for i in region.itertuples(index=False,name='Region'):\n",
    "        region_chr,region_start,region_end,region_size,region_index = i\n",
    "        df['chrom'] = df['chrom'].apply(lambda x:str(x))\n",
    "        query_text = f'(chrom == @region_chr) and ({column} > @region_start) and ({column} <=  @region_end)'\n",
    "        df_region_filter_temp = df.query(query_text)\n",
    "        df_region_filter_temp['region_start'] = region_start\n",
    "        df_region_filter_temp['region_end'] = region_end\n",
    "        df_region_filter_temp['region_index'] = region_index\n",
    "        df_cut,df_bins= pd.cut(df_region_filter_temp[column],bins=range(region_start,region_end+binsize-1,binsize),precision=0,retbins=True)\n",
    "        df_region_filter_temp['interval']  = df_cut\n",
    "        df_region_filter_merge = df_region_filter_merge.append(df_region_filter_temp)\n",
    "        #add into intervals in region without target values calculated\n",
    "        chrinterval_tmp = pd.DataFrame(pd.cut(np.arange(region_start+binsize,region_end+binsize,binsize),bins=df_bins,precision=0),columns = ['interval'])\n",
    "        chrinterval_tmp['chrom'] = region_chr\n",
    "        chrinterval_tmp['region_index'] = region_index\n",
    "        chrinterval_all = chrinterval_all.append(chrinterval_tmp)\n",
    "        df_bins_dict[region_index] = df_bins\n",
    "    df_count = df_region_filter_merge.groupby(by=['region_index','interval']).count()[column]\n",
    "    df_count.rename(f'{column}_count',inplace=True)\n",
    "    return df_count,df_region_filter_merge,chrinterval_all,df_bins_dict\n",
    "\n",
    "def region_reads(region):\n",
    "    region_df = pd.read_csv(region,sep=\"\\t\",header=None,usecols=[0,1,2],names=['chrom','start','end'],converters={'chrom':str,'start':int,'end':int},comment=\"#\")\n",
    "    region_df['size'] = region_df['end']-region_df['start']\n",
    "    region_df['region_index'] = region_df.index\n",
    "    return region_df\n",
    "\n",
    "def anchor_detail(anchor,df_merge_part,prefix):\n",
    "    anchor_reads_all_df = pd.DataFrame([])\n",
    "    for i in anchor.itertuples(index=False, name='Anchor'):\n",
    "        #v2.3_9.1 input anchor files with name\n",
    "        anchor_chr,anchor_start,anchor_end,anchor_name = i\n",
    "        #filter out the alignment that related to the anchor sites\n",
    "        criteria = '(chrom == @anchor_chr) and (pos <= @anchor_end) and (pos >= @anchor_start)'\n",
    "        anchor_alignment = df_merge_part.query(criteria)\n",
    "        anchor_alignment.to_csv(f'{prefix}_anchor_alignment.csv',sep='\\t')\n",
    "        \n",
    "        #get the related reads \n",
    "        #filter out all alignments related to anchor sites related reads\n",
    "        anchor_reads_list = list(anchor_alignment['read_name'])\n",
    "        anchor_reads_df = df_merge_part.query('read_name in @anchor_reads_list')\n",
    "        \n",
    "        if len(anchor_reads_df) != 0:\n",
    "            #mark the anchor alignment with anchor name,\n",
    "            anchor_reads_df.loc[anchor_reads_df.eval(criteria),'anchor_name'] = anchor_name\n",
    "            anchor_reads_all_df = anchor_reads_all_df.append(anchor_reads_df,ignore_index=True)\n",
    "    \n",
    "    anchor_reads_all_df.loc[:,'anchor_name'] = anchor_reads_all_df.loc[:,'anchor_name'].fillna('normal')\n",
    "    anchor_reads_detail_df = anchor_reads_all_df.query('anchor_name != \"normal\"')\n",
    "    \n",
    "    anchor_reads_all_df.to_csv(f'{prefix}_anchor_reads_all.csv',sep='\\t')\n",
    "    anchor_reads_detail_df.to_csv(f'{prefix}_anchor_reads_detial.csv',sep='\\t')\n",
    "    \n",
    "    return anchor_reads_detail_df\n",
    "\n",
    "\n",
    "def anchor_statics(anchor_reads_detial_df,prefix):\n",
    "    anchor_detial_site_nunique = anchor_reads_detial_df.groupby('read_name')['anchor_name'].nunique()\n",
    "    anchor_detial_site_nunique.value_counts().to_csv(f'{prefix}_anchor_valuecount.csv',sep='\\t')\n",
    "    anchor_and2_list = anchor_detial_site_nunique[anchor_detial_site_nunique>=2].index.to_list()\n",
    "    anchor_and2_detail = anchor_reads_detial_df.query('read_name in @anchor_and2_list')\n",
    "    #only calculte the combination, would not calculate if the interaction caused by repeats of same anchor sites\n",
    "    anchor_and2_detail_dropdu = anchor_and2_detail.drop_duplicates(['read_name','anchor_name'])\n",
    "    \n",
    "    for hubsize in [2,3,4]:\n",
    "        anchor_detial_combinations = anchor_and2_detail_dropdu.groupby('read_name').apply(lambda x : list(itertools.combinations(x['anchor_name'],hubsize)))\n",
    "        anchor_comb_list = list(itertools.chain(*anchor_detial_combinations))\n",
    "        anchor_comb_df = pd.DataFrame.from_dict(dict(Counter(anchor_comb_list)),orient='index')\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        if len(anchor_comb_df) >= 1:\n",
    "            anchor_comb_df.sort_index().plot(kind='bar',ax=ax)\n",
    "            ax.legend_.remove()\n",
    "            plt.savefig(f'{prefix}_{hubsize}.png',format = 'png',dpi=300,bbox_inches = 'tight')\n",
    "            anchor_comb_df.to_csv(f'{prefix}_{hubsize}.csv')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "def anchor_reads(anchor,anchor_reads_detial_df,df_merge_part,region,column,binsize,anchor_mode,prefix,write,**others):\n",
    "    anchor_detial_site_nunique = anchor_reads_detial_df.groupby('read_name')['anchor_name'].nunique()\n",
    "    \n",
    "    if anchor_mode[:3] == 'and':\n",
    "        anchorcount = int(anchor_mode[3:])\n",
    "    elif anchor_mode == 'all':\n",
    "        anchorcount = len(anchor)\n",
    "    elif anchor_mode == 'or':\n",
    "        anchorcount = 1\n",
    "        \n",
    "    #step sample according to the combinations of anchors, for cluster heatmap drawing\n",
    "    \n",
    "    anchor_and2_list = anchor_detial_site_nunique[anchor_detial_site_nunique>=anchorcount].index.to_list()\n",
    "    anchor_and2_detail = anchor_reads_detial_df.query('read_name in @anchor_and2_list')\n",
    "    anchor_and2_detail_dropdu = anchor_and2_detail.drop_duplicates(['read_name','anchor_name'])\n",
    "    df_comb = pd.DataFrame([])\n",
    "    for i in range(anchorcount,len(anchor)+1):\n",
    "        anchor_detial_combinations = pd.DataFrame(anchor_and2_detail_dropdu.groupby('read_name').apply(lambda x : list(itertools.combinations(x['anchor_name'],i))))\n",
    "        #print(anchor_detial_combinations)\n",
    "        anchor_detial_combinations_dropmu = anchor_detial_combinations[anchor_detial_combinations[0].apply(lambda x:len(x)==1)]\n",
    "        df_comb = df_comb.append(anchor_detial_combinations_dropmu)\n",
    "    df_comb['new'] = df_comb[0].apply(lambda x: x[0])\n",
    "    \n",
    "    if others['step_sample'] is not None:\n",
    "        sample_frac = others['step_sample']\n",
    "        df_comb_sample = df_comb.groupby(by='new').sample(frac=sample_frac)\n",
    "        df_comb_sample.to_csv(f'{prefix}_comb_sample_frac{sample_frac}.csv')\n",
    "        anchor_and_list = df_comb_sample.index.to_list()\n",
    "    else:\n",
    "        #print('why_no_comb?')\n",
    "        df_comb.to_csv(f'{prefix}_comb_sample.csv')\n",
    "        anchor_and_list = anchor_detial_site_nunique[anchor_detial_site_nunique>=anchorcount].index.to_list()\n",
    "        \n",
    "#include the alignment informaiton with anchored reads, not the samle of anchor_reads_detial_df\n",
    "    anchor_merge = df_merge_part.query('read_name in @anchor_and_list')\n",
    "    anchor_interval_count,anchor_filter_merge,*anchr_rest = chr_interval(anchor_merge,region,'pos',binsize)\n",
    "    \n",
    "    if (len(anchor_filter_merge) != 0) and (write == True):\n",
    "        anchor_filter_merge.to_csv(f'{prefix}_anchor_filter_merge.csv',sep='\\t')\n",
    "        return anchor_interval_count,anchor_filter_merge,anchor_and_list\n",
    "    \n",
    "    else:\n",
    "        with open (f'{prefix}.report','a+') as report:\n",
    "            report.write('No reads match anchor')\n",
    "            exit()\n",
    "        \n",
    "def anchor_calcu(merge_keepall_part,anchor_interval_count,region_df,binsize,prefix,write):        \n",
    "    binnor_interval_count,*binnor_rest,chrinterval_all,df_bins_dict= chr_interval(merge_keepall_part,region_df,'site',binsize)\n",
    "    anchor_binnor_merge = pd.merge(anchor_interval_count,binnor_interval_count,on = ['interval','region_index'],how='left')\n",
    "    #filter out region with coverage less than 5 \n",
    "    anchor_binnor_merge.loc[anchor_binnor_merge['site_count'] <5 ,'site_count'] = 0 \n",
    "    anchor_binnor_merge = anchor_binnor_merge.assign(\n",
    "        bin_nor = lambda x: x['pos_count']/x['site_count']\n",
    "    ).dropna()\n",
    "    \n",
    "    #anchor_binnor_merge.eval('bin_nor=pos_count/site_count',inplace=True)\n",
    "    anchor_binnor_merge_all = pd.merge(anchor_binnor_merge,chrinterval_all,on = ['interval','region_index'],how='right') \\\n",
    "                              .fillna({'pos_count':0,'site_count':0,'bin_nor':0})\n",
    "    anchor_binnor_merge_all['bin_logy'] = np.log10(anchor_binnor_merge_all['pos_count']+1)\n",
    "    anchor_binnor_merge_all['bin_nor_logy'] = np.log10(anchor_binnor_merge_all['bin_nor']+1)\n",
    "    anchor_binnor_merge_all_sort = anchor_binnor_merge_all.sort_values(by=['region_index','interval']).reset_index()\n",
    "    if write == True:\n",
    "        anchor_binnor_merge_all_sort.to_csv(f'{prefix}_anchor_binnor_merge_all.csv',index = None, sep='\\t')\n",
    "    \n",
    "    return anchor_binnor_merge_all_sort\n",
    "\n",
    "def heatmap_line(i,j,anchor_filter_merge):\n",
    "    heat = anchor_filter_merge[anchor_filter_merge['region_index']==i].groupby(by=['read_name','interval']).count()['pos'].astype(np.int16).unstack().fillna(0)\n",
    "    heat_T = heat.T\n",
    "    heat_a = pd.merge(heat_T,j,on='interval',how ='outer').sort_values(by='interval')\n",
    "    heat_b = heat_a.T.fillna(0)\n",
    "    heat_b.drop(['interval'],axis=0,inplace=True)\n",
    "    heat_c = heat_b\n",
    "    heat_c.columns = np.arange(len(j))\n",
    "    reads = anchor_filter_merge['read_name'].drop_duplicates().sort_values()\n",
    "    heat_d = pd.merge(reads,heat_c,left_on='read_name',right_index=True,how ='left').fillna(0).sort_values(by='read_name')\n",
    "    heat_d.index = np.arange(len(heat_d))\n",
    "    return heat_d\n",
    "\n",
    "\n",
    "def heat_df(anchor_binnor_merge_all_sort,anchor_filter_merge):\n",
    "    anchor_binnor_merge_all_group = anchor_binnor_merge_all_sort.groupby('region_index')\n",
    "    heat_concat = pd.DataFrame([])\n",
    "    read_concat = pd.DataFrame([])\n",
    "    for i,j in anchor_binnor_merge_all_group:\n",
    "        heat_d = heatmap_line(i,j,anchor_filter_merge)\n",
    "        #for cluster slice\n",
    "        heat_concat = pd.concat([heat_concat,heat_d.iloc[:,1:]],axis=1)\n",
    "        read_concat = pd.concat([read_concat,heat_d.iloc[:,0]],axis=1)\n",
    "    return heat_concat,read_concat\n",
    "\n",
    "#drawing functions        \n",
    "def remove_draw(ax,**remove_dict):\n",
    "    if remove_dict['tick'] == True:\n",
    "        ax.tick_params(\n",
    "        axis='x',          \n",
    "        which='both',      \n",
    "        bottom=False,     \n",
    "        top=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        direction='inout') \n",
    "    if remove_dict['spine'] == True:\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "    if remove_dict['locator'] == True:\n",
    "        ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "        ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "def porec_draw(df,ax,calcute,plotkind,ylim):\n",
    "    ax.set_xlabel('')\n",
    "    remove_draw(ax,tick=True,spine=True,locator=False)\n",
    "    df_len = len(df)\n",
    "    useColDt = dict(raw='pos_count', logy=\"bin_logy\", binnor=\"bin_nor\",binnorlogy ='bin_nor_logy' )\n",
    "    colorDt = dict(raw='darkgreen', logy=\"purple\", binnor=\"#ED6D00\", binnorlogy = 'steelblue')\n",
    "    titleDt = dict(\n",
    "        raw='Contact Count', \n",
    "        logy=\"log${_10}$(Contact Count + 1)\", \n",
    "        binnorlogy = \"log${_10}$(Normalized Contact Count + 1)\",\n",
    "        binnor=\"Contact Count Ratio\"\n",
    "    )\n",
    "    useCol = useColDt[calcute]\n",
    "    plotDt = {}\n",
    "    if plotkind == 'bar':\n",
    "        plotDt['width'] = 0.9\n",
    "\n",
    "    plotDt['kind'] = plotkind\n",
    "    if ylim is not None:\n",
    "        if calcute == 'logy':\n",
    "            plotDt['ylim'] = (0,np.log10(float(ylim)))\n",
    "        else:\n",
    "            plotDt['ylim'] = (0,float(ylim))\n",
    "\n",
    "    plotDt['xlim'] = (0,df_len+1)\n",
    "    plotDt['color'] = colorDt[calcute]\n",
    "        \n",
    "    #parameters can be load in in dict way\n",
    "    df[useCol].plot(**plotDt)\n",
    "    ax.set_ylabel(titleDt[calcute])\n",
    "\n",
    "def site_temp(s,region_df,binsize):\n",
    "    site = pd.read_csv(s,header=None,sep='\\t',names=['chrom','site'],converters={'chrom':str, 'site':int},comment=\"#\")\n",
    "    site_interval_count,_1,chrinterval_all,_2 = chr_interval(site,region_df,'site',binsize)\n",
    "    site_interval_count_df = site_interval_count.reset_index()\n",
    "    site_interval_count_merge = pd.merge(site_interval_count_df,chrinterval_all,how='right').sort_values(by=['chrom','interval']).fillna({'site_count':0})\n",
    "    site_result = site_interval_count_merge['site_count']\n",
    "    return site_result\n",
    "\n",
    "    \n",
    "def bg_temp(bg,region,binsize):\n",
    "    bed_graph = pd.read_csv(bg,header=None,sep='\\t',names=['chrom','start','end','values'],converters={'chrom':str,'start':int,'end':int,'values':float},comment=\"#\")\n",
    "    bed_graph.eval('result = (end-start)*values',inplace=True)\n",
    "\n",
    "    _1,bg_region_filter_start,chrinterval_all,_2 = chr_interval(bed_graph,region,'start',binsize) \n",
    "    _3,bg_region_filter_end,*others = chr_interval(bed_graph,region,'end',binsize) \n",
    "\n",
    "    bg_region_filter_start.rename(columns={'interval':'start_interval'},inplace=True)\n",
    "    bg_region_filter_end.rename(columns={'interval':'end_interval'},inplace=True)\n",
    "    bg_region_filter_start_end = pd.merge(bg_region_filter_start,bg_region_filter_end,how='outer')\n",
    "\n",
    "    #not_equeal\n",
    "    bg_region_filter_start_end_notequal = bg_region_filter_start_end[bg_region_filter_start_end['start_interval']!=bg_region_filter_start_end['end_interval']]\n",
    "    def middle_point(a,b):\n",
    "        if type(a) == pd._libs.interval.Interval:\n",
    "            return a.right\n",
    "        elif type(b) == pd._libs.interval.Interval:\n",
    "            return b.left\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    bg_region_filter_start_end_notequal['middle_point'] = bg_region_filter_start_end_notequal.apply(lambda row: middle_point(row['start_interval'],row['end_interval']),axis=1).astype(int)\n",
    "    bg_region_filter_start_end_notequal['start'] = bg_region_filter_start_end_notequal['start'].astype(int)\n",
    "    bg_region_filter_start_end_notequal['end'] = bg_region_filter_start_end_notequal['end'].astype(int)\n",
    "    bg_region_filter_start_end_notequal.eval('start_dist_part=result*(middle_point-start)/(end-start)',inplace=True,engine='python')\n",
    "    bg_region_filter_start_end_notequal.eval('end_dist_part=result*(end-middle_point)/(end-start)',inplace=True,engine='python')\n",
    "\n",
    "    bg_region_filter_notequal_a = bg_region_filter_start_end_notequal.loc[:,('chrom','start_interval','start_dist_part')].rename(columns={'start_interval':'interval','start_dist_part':'result'})\n",
    "    bg_region_filter_notequal_b = bg_region_filter_start_end_notequal.loc[:,('chrom','end_interval','end_dist_part')].rename(columns={'end_interval':'interval','end_dist_part':'result'})\n",
    "\n",
    "    #equal\n",
    "    bg_region_filter_start_end_equal = bg_region_filter_start_end[bg_region_filter_start_end['start_interval']==bg_region_filter_start_end['end_interval']]\n",
    "    bg_region_filter_start_end_equal_part = bg_region_filter_start_end_equal.loc[:,('chrom','start_interval','result')].rename(columns={'start_interval':'interval'})\n",
    "\n",
    "    #all\n",
    "    bg_region_filter_start_end_all = pd.concat([bg_region_filter_notequal_a,bg_region_filter_notequal_b,bg_region_filter_start_end_equal_part])\n",
    "    bg_region_filter_start_end_all_drop_sort=bg_region_filter_start_end_all[~bg_region_filter_start_end_all['interval'].isin([0])].sort_values(by=['chrom','interval'])\n",
    "    bg_region_filter_start_end_all_final = pd.merge(bg_region_filter_start_end_all_drop_sort,chrinterval_all,on=['chrom','interval'],how='right').fillna({'result':0})\n",
    "    \n",
    "    #sum\n",
    "    bg_result = bg_region_filter_start_end_all_final.groupby(by=['chrom','interval']).sum()['result'].reset_index()['result']\n",
    "    return bg_result\n",
    "\n",
    "        \n",
    "def track_draw(track_list,track_labels,track_ylims,mainplot,region_df,binsize,gs,color_order,kind):\n",
    "    color_list = ['#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf','#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    track_order = 0\n",
    "    for track in track_list: \n",
    "        ax_track = mainplot.add_subplot(gs[track_order])\n",
    "        ax_track.set_xlabel('')\n",
    "        ax_track.set_ylabel(track_labels[track_order])\n",
    "        #ax_track.yaxis.set_label_coords(-0.05,0.6)\n",
    "        remove_draw(ax_track,tick=True,spine=True,locator=False)\n",
    "        if kind == 'bg':\n",
    "            track_result = bg_temp(track,region_df,binsize)\n",
    "        elif kind == 'site':\n",
    "            track_result = site_temp(track,region_df,binsize)\n",
    "        \n",
    "        TrackDt = {}\n",
    "        TrackDt['kind'] = 'bar'\n",
    "        TrackDt['width'] = 0.9\n",
    "        TrackDt['ax'] = ax_track\n",
    "        TrackDt['color'] = color_list[track_order+color_order]\n",
    "        \n",
    "        if track_ylims:\n",
    "            ylim_up = track_ylims[track_order]\n",
    "            if ylim_up != None:                       \n",
    "                TrackDt['ylim'] = (0,float(ylim_up))\n",
    "        \n",
    "        track_result.plot(**TrackDt)\n",
    "        track_order += 1\n",
    "\n",
    "def gene_model_draw(ax,gene_isoform,region_iter,yflen):\n",
    "    region_chr,region_start,region_end,region_size,region_index,region_cum = region_iter\n",
    "    gene_isoform['chrom'] = gene_isoform['chrom'].apply(lambda x:str(x))\n",
    "    gene_isoform_sub = gene_isoform.query('(chrom == @region_chr) and (chromEnd>=@region_start) and (chromStart <= @region_end)')\n",
    "    gene_isoform_sub['gene_id'] = gene_isoform['name'].map(lambda x: x.split('.')[0])\n",
    "    gene_isoform_sub_part =  gene_isoform_sub.loc[:,('chrom','chromStart','chromEnd','strand','thickStart','thickEnd','blockCount','blockSizes','blockStarts','gene_id')]\n",
    "    \n",
    "    for gene in gene_isoform_sub_part.itertuples():\n",
    "        _,gene_chr,gene_start,gene_end,gene_strand,gene_thickStart,gene_thickEnd,gene_blockCount,temp_blockSizes,temp_blockStarts,gene_id = gene\n",
    "        gene_blockSizes = np.fromstring(temp_blockSizes, sep=',', dtype='int')\n",
    "        gene_blockStarts = np.fromstring(temp_blockStarts, sep=',', dtype='int') + gene_start\n",
    "\n",
    "        gene_size = gene_end - gene_start\n",
    "        gene_color = 'k'\n",
    "        arrowprops = dict(arrowstyle=\"-|>\", connectionstyle=\"angle\", color = gene_color)\n",
    "        \n",
    "        height = 0.075/yflen\n",
    "        bottom = 0.60/yflen\n",
    "        \n",
    "        \n",
    "        if gene_strand == '+':\n",
    "            ax.annotate('', xy=(gene_start+gene_size/10, bottom + height*2), xytext=(gene_start, bottom), arrowprops=arrowprops)\n",
    "        else:\n",
    "            ax.annotate('', xy=(gene_end-gene_size/10, bottom + height*2), xytext=(gene_end, bottom), arrowprops=arrowprops)\n",
    "        \n",
    "        \n",
    "        gene_block = mp.Rectangle((gene_start,bottom),gene_size,0.02/yflen,color=gene_color, linewidth=0)\n",
    "        ax.add_patch(gene_block)\n",
    "        \n",
    "        #ax.plot([gene_start, gene_end], [0, 0], color = gene_color)\n",
    "        for exonstart, size in zip(gene_blockStarts, gene_blockSizes):\n",
    "            if (exonstart == gene_start) and (exonstart+size == gene_end):\n",
    "                utr_size = gene_thickStart-gene_start\n",
    "                utr = mp.Rectangle((exonstart, bottom + 0-height/2), utr_size, height, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(utr)\n",
    "                utr_size = gene_end-gene_thickEnd\n",
    "                utr = mp.Rectangle((gene_thickEnd, bottom + 0-height/2), utr_size, height, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(utr)\n",
    "                exon = mp.Rectangle((gene_thickStart, bottom + 0-height), gene_thickEnd-gene_thickStart, height*2, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(exon)\n",
    "            elif exonstart + size <= gene_thickStart:\n",
    "                # only 5'/ 3'UTR\n",
    "                utr = mp.Rectangle((exonstart, bottom + 0-height/2), size, height, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(utr)\n",
    "            elif (exonstart < gene_thickStart) and (exonstart + size > gene_thickStart):\n",
    "                # exon with 5' / 3' UTR \n",
    "                utr_size = gene_thickStart-exonstart\n",
    "                utr = mp.Rectangle((exonstart, bottom + 0-height/2), utr_size, height, color=gene_color, linewidth=0)\n",
    "                exon = mp.Rectangle((exonstart+utr_size, bottom + 0-height), size-utr_size, height*2, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(utr)\n",
    "                ax.add_patch(exon)\n",
    "            elif (exonstart >= gene_thickStart) and (exonstart + size <= gene_thickEnd):\n",
    "                # regular exon\n",
    "                exon = mp.Rectangle((exonstart, bottom + 0-height), size, height*2, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(exon)\n",
    "            elif (exonstart < gene_thickEnd) and (exonstart + size) > gene_thickEnd:\n",
    "                # exon with 3' / 5' UTR\n",
    "                utr_size = exonstart + size - gene_thickEnd\n",
    "                utr = mp.Rectangle((gene_thickEnd, bottom + 0-height/2), utr_size, height, color=gene_color, linewidth=0)\n",
    "                exon = mp.Rectangle((exonstart, bottom + 0-height), size-utr_size, height*2, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(utr)\n",
    "                ax.add_patch(exon)\n",
    "            elif exonstart >= gene_thickEnd:\n",
    "                # only 3'/ 5'UTR\n",
    "                utr = mp.Rectangle((exonstart, bottom + 0-height/2), size, height, color=gene_color, linewidth=0)\n",
    "                ax.add_patch(utr)\n",
    "\n",
    "            ax.annotate(gene_id, xy=((gene_start+gene_end)/2, bottom+height*2.5), ha='center')\n",
    "            \n",
    "def rec_part(region_iter,df,kind,ax,binsize,yflen,**other):\n",
    "    region_chr,region_start,region_end,region_size,region_index,region_cum = region_iter\n",
    "    df['chrom'] = df['chrom'].apply(lambda x:str(x))\n",
    "    df_sub = df.query('(chrom == @region_chr) and (end >= @region_start) and (start <= @region_end)')\n",
    "    df_sub = df[df['chrom']==region_chr]\n",
    "    for k in df_sub.itertuples(index=False):\n",
    "        if kind == 'mark':\n",
    "            df_chr,df_start,df_end,df_name,df_color = k\n",
    "            bottom = 0.20/yflen\n",
    "            ec_color = 'black'\n",
    "        if kind == 'anchor':\n",
    "            df_chr,df_start,df_end,df_name = k\n",
    "            df_color = '#C00000'\n",
    "            bottom = 0.40/yflen\n",
    "            ec_color = '#C00000'\n",
    "        \n",
    "        left = df_start\n",
    "        width = df_end - df_start + 1\n",
    "        ax.add_patch(plt.Rectangle((left,bottom),width,0.075/yflen,color=df_color,ec = ec_color))\n",
    "        remove_draw(ax,tick=False,spine = False,locator = False)\n",
    "        ax.spines.top.set_visible(False)\n",
    "        for axis in ['left','bottom','right']:\n",
    "            ax.spines[axis].set_alpha(0.7)\n",
    "            ax.spines[axis].set_color('#bdbebd')\n",
    "        \n",
    "        ax.set_xlabel(f'{region_chr}')\n",
    "        ax.patch.set_alpha(0)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(left=region_start,right=region_end)\n",
    "        x_ticks = np.arange(region_start,region_end,10*binsize)\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels(x_ticks,rotation=45,ha='right')\n",
    "            \n",
    "def rec_draw(region_df_cum,mainplot,anchor,binsize,gs,yflen,anchormode,**other):\n",
    "    last_cum = 0\n",
    "    for region_iter in region_df_cum.itertuples(index=False):\n",
    "        region_cum = region_iter[-1]\n",
    "        ax_rec = mainplot.add_subplot(gs[0,last_cum:region_cum])\n",
    "        if other is not None:\n",
    "            if 'gene' in other:\n",
    "                gene_model_draw(ax_rec,other['gene'],region_iter,yflen)\n",
    "            if 'mark' in other:\n",
    "                rec_part(region_iter,other['mark'],'mark',ax_rec,binsize,yflen)\n",
    "        rec_part(region_iter,anchor,'anchor',ax_rec,binsize,yflen)\n",
    "        last_cum = region_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:26:31.236972Z",
     "start_time": "2021-12-28T07:25:56.864146Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'porecplot_draw_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3ac5b4e9ffee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mporecplot_draw_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'porecplot_draw_func'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import porecplot_draw_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:26:52.001023Z",
     "start_time": "2021-12-28T07:26:39.317394Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A':[12,45,21,67,1,2],'B':[22,31,2,4,1,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:27:28.645369Z",
     "start_time": "2021-12-28T07:27:28.465543Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['A']<=2,'A'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:27:30.463947Z",
     "start_time": "2021-12-28T07:27:30.379106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B\n",
       "0  12  22\n",
       "1  45  31\n",
       "2  21   2\n",
       "3  67   4\n",
       "4   0   1\n",
       "5   0   7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coolcoots_k",
   "language": "python",
   "name": "cooltools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
