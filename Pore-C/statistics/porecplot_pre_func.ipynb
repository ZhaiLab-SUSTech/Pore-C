{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:01:45.485686Z",
     "start_time": "2021-12-28T07:01:41.192335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /public/home/lizw/task/pore_c/tools/porecscripts/v2.14/porecplot_pre_func.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/public/home/lizw/task/pore_c/tools/porecscripts/v2.14/porecplot_pre_func.py'\n",
    "\n",
    "#@Author: Zhuowen Li\n",
    "#@LastEdit: 2021/9/30 下午1:37:37\n",
    "#@Version: \n",
    "#@Description: small modification on color,etc.\n",
    "\n",
    "#@Author: Zhuowen Li\n",
    "#@LastEdit: 2021/9/22 下午3:10:26\n",
    "#@Version: v2.9\n",
    "#@Description: output singleton for formalization\n",
    "\n",
    "#@Author: Zhuowen Li\n",
    "#@LastEdit: 2021/9/10 下午1:13:53\n",
    "#@Version: v2.8\n",
    "#@Description: \n",
    "#1 update hic pre-processing file from pairsam files\n",
    "#2 parquet instead of feather\n",
    "\n",
    "#@Author: Zhuowen Li\n",
    "#@LastEdit: 2021/8/4 下午2:32:46\n",
    "#@Version: V2.3\n",
    "#@Description: Prepare the tables for porecplot drawing, and basic statistic analysis of Pore-C data. \n",
    "#@Modifications: 1.fix the order distribtuion draw 2. split pair\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from pathlib import PurePath\n",
    "import seaborn as sns\n",
    "import pypairix\n",
    "\n",
    "from typing import (\n",
    "    Tuple,\n",
    ")\n",
    "\n",
    "#font setting\n",
    "import matplotlib.font_manager as font_manager\n",
    "font_dirs = [\"/public/home/lizw/software/font\"]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "def divide_order(x):\n",
    "    if x <= 3:\n",
    "        return str(x)\n",
    "    elif (x == 4) or (x == 5):\n",
    "        return '4-5'\n",
    "    elif 6<=x<=10:\n",
    "        return '6-10'\n",
    "    elif 11<=x<=20:\n",
    "        return '11-20'\n",
    "    elif x > 20:\n",
    "        return '20+'\n",
    "             \n",
    "def porec_merge(order:int,mpq:int,porec_dir:str,prefix:str,outdir:str) -> Tuple[pd.DataFrame,pd.DataFrame,pd.DataFrame]:\n",
    "    align_dir = Path(PurePath(porec_dir,'align_table'))\n",
    "    align_dir_porec_generator = align_dir.glob(prefix + \"*pore_c.parquet\")\n",
    "    align_batch_porec_merge_df = pyarrow.concat_tables(list(map(pq.read_table,align_dir_porec_generator))).to_pandas()\n",
    "    \n",
    "    align_batch_porec_merge_df_pass = align_batch_porec_merge_df.query('pass_filter==True').query('mapping_quality>=@mpq')\n",
    "    align_batch_porec_merge_df_singleton = align_batch_porec_merge_df.query(\"filter_reason=='singleton'\").query('mapping_quality>=@mpq')\n",
    "\n",
    "    align_allorder = pd.concat([align_batch_porec_merge_df_pass,align_batch_porec_merge_df_singleton],axis=0)\n",
    "    \n",
    "    #Importmant fixation in V2.1\n",
    "    #According to PoreC : We refer to the set of filtered alignments associated with a given Pore-C read as a (multi-way) contact, and the number of fragments associated with a contact as its order.\n",
    "    #When multiple alignment in the same read align to the same fragment, it would count multiple times when calculating order\n",
    "    #Example fragmeng_id in read1 listed like this: 1,2,3,2,2,3,0   the order is 7 rather than just counting the fragment types. \n",
    "    align_allorder['order'] = align_allorder.groupby(\"read_name\")['fragment_id'].transform('count')\n",
    "    #use the mid point as final position: ref: ~/software/Pore-C-Snakemake_10Feb/.snakemake/conda/c2039cdc/lib/python3.8/site-packages/pore_c/analyses/contacts.py\n",
    "    \n",
    "    #modified according to porec_tools\n",
    "    align_allorder = align_allorder.assign(\n",
    "        pos = lambda x: np.rint((x.fragment_start + x.fragment_end)*0.5)\n",
    "        .astype(int)\n",
    "        )\n",
    "    \n",
    "    read_info =  align_allorder.reindex(columns=['read_name','read_length','order']).drop_duplicates()\n",
    "    list_sorted = ['1','2','3','4-5','6-10','11-20','20+']\n",
    "    read_info['divide_order'] = read_info['order'].apply(divide_order).astype('category').cat.set_categories(list_sorted) \n",
    "    #calculate the reads order distribution after drop duplicates\n",
    "    order_count = read_info['order']\n",
    "    read_info_outpath = PurePath(outdir,f'{prefix}.read_info.csv')\n",
    "    read_info.to_csv(read_info_outpath)\n",
    "    \n",
    "    #pair_slice\n",
    "    readID_order_map = read_info.groupby('divide_order')['read_name']\n",
    "    pair_dir = Path(PurePath(porec_dir,'pairs'))\n",
    "    pair_file = str(list(pair_dir.glob(prefix + \"*.sorted.pairs.gz\"))[0])\n",
    "    pair_table = pd.read_table(\n",
    "        pair_file,                     \n",
    "        comment=\"#\",             \n",
    "        compression='gzip',\n",
    "        names=['readID','chr1','pos1','chr2','pos2','strand1','strand2','pair_type','align1_idx','align2_idx','distance_on_read']\n",
    "    )\n",
    "\n",
    "    pair_table.replace({'readID': {'read|_[0-9]+': ''}},regex=True,inplace=True)\n",
    "    pair_comment = pypairix.open(pair_file).get_header()\n",
    "\n",
    "    for a,b in readID_order_map:\n",
    "        pair_slice = pair_table.query('readID in @b')\n",
    "        if len(pair_slice) != 0:\n",
    "            pair_order_path = PurePath(outdir,f'{prefix}.order_{a}.pair')\n",
    "            with open(pair_order_path,'w+') as pair_out:\n",
    "                pair_out.write('\\n'.join(pair_comment))\n",
    "                pair_out.write('\\n')\n",
    "            pair_slice.to_csv(pair_order_path,header=None,index=None,mode='a',sep=\"\\t\")\n",
    "                              \n",
    "    #align_merge                                                                       \n",
    "    align_merge_order_filter =  align_allorder.query('order>= @order')\n",
    "    align_merge_order_filter_part = align_merge_order_filter.reindex(columns=['chrom','read_name','pos'])\n",
    "    \n",
    "    porec_merge_part_outpath = PurePath(outdir,f'{prefix}.order_{order}_merge_part.parquet')\n",
    "    align_merge_order_filter_part.reset_index().to_parquet(porec_merge_part_outpath)\n",
    "    \n",
    "    #merge_keepall\n",
    "    merge_keepall = align_allorder.query('order >=1')\n",
    "    merge_keepall_part = merge_keepall.reindex(columns=['chrom','pos'])\n",
    "    merge_keepall_part.sort_values(by=['chrom','pos'],inplace=True)\n",
    "    \n",
    "    singleton = align_allorder.query('order == 1')\n",
    "    singleton_part = singleton.reindex(columns=['chrom','pos'])\n",
    "    singleton_part.sort_values(by=['chrom','pos'],inplace=True)\n",
    "    \n",
    "    porec_keepall_outpath = PurePath(outdir,f'{prefix}.order_{order}_sorted_orderall_fornormailize.parquet')\n",
    "    merge_keepall_part.reset_index().to_parquet(porec_keepall_outpath)\n",
    "    \n",
    "    singleton_outpah = PurePath(outdir,f'{prefix}.order_{order}_sorted_singleton_fornormailize.parquet')\n",
    "    singleton_part.reset_index().to_parquet(singleton_outpah)\n",
    "    \n",
    "    return order_count,align_allorder,read_info\n",
    "\n",
    "def pair_merge(pairfile,prefix,outdir):\n",
    "    pairdf = pd.read_csv(pairfile,compression='gzip',sep=\"\\t\",comment=\"#\",usecols=[0,1,2,3,4],names=['read_name','chrom1', 'pos1', 'chrom2', 'pos2'])\n",
    "    pairdf1 = pairdf.reindex(['read_name','chrom1','pos1'],axis=1)\n",
    "    pairdf2 = pairdf.reindex(['read_name','chrom2','pos2'],axis=1)\n",
    "    pairdf1.columns=['read_name','chrom','pos']\n",
    "    pairdf2.columns=['read_name','chrom','pos']\n",
    "    pairdf_position = pd.concat([pairdf1,pairdf2])\n",
    "    pairdf_position_sorted = pairdf_position.sort_values('read_name')\n",
    "\n",
    "    hic_merge_part_outpath = PurePath(outdir,f'{prefix}.hic_merge_part.parquet')\n",
    "    pairdf_position_sorted.reset_index().to_parquet(hic_merge_part_outpath)\n",
    "\n",
    "    #merge_keepall\n",
    "    merge_keepall_part = pairdf_position_sorted.reindex(columns=['chrom','pos'])\n",
    "    merge_keepall_part.sort_values(by=['chrom','pos'],inplace=True)\n",
    "    hic_keepall_outpath = PurePath(outdir,f'{prefix}.hic_sorted_orderall_fornormailize.parquet')\n",
    "    merge_keepall_part.reset_index().to_parquet(hic_keepall_outpath)\n",
    "\n",
    "def orderdistri(order_count,prefix,outdir):\n",
    "    f, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_title('Contact order distribution')\n",
    "    ax.set_xlabel(\"Contact order\")\n",
    "    ax.set_ylabel(\"Frequency Density\")\n",
    "    ax.set_xlim(0,30)\n",
    "    bins_count = order_count.max()\n",
    "    order_count.hist(bins=np.arange(bins_count+1)-0.5,ax=ax,density=1,edgecolor = 'w',color='#4CB391')\n",
    "    orderdistri_outpath = PurePath(outdir,f'{prefix}_Contact_order_distribution.png')\n",
    "    plt.savefig(orderdistri_outpath,format = 'png',dpi=300,bbox_inches = 'tight')\n",
    "\n",
    "def lengthdistri(align_allorder,prefix,outdir):\n",
    "    f, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_title('Read length distribution')\n",
    "    ax.set_xlabel(\"Read length\")\n",
    "    ax.set_ylabel(\"Frequency Density\")\n",
    "    ax.set_xlim(0,15000)\n",
    "    bins_count = align_allorder['read_length'].max()//500\n",
    "    align_allorder['read_length'].hist(bins=bins_count+1,ax=ax,density=1,edgecolor = 'w',color='#4CB391')\n",
    "    lengthdistri_outpath = PurePath(outdir,f'{prefix}_Read_length_distribution.png')\n",
    "    plt.savefig(lengthdistri_outpath,format = 'png',dpi=300,bbox_inches = 'tight')\n",
    "\n",
    "def lenorderbox(read_info,prefix,outdir):\n",
    "    f, ax = plt.subplots(figsize=(25,8))\n",
    "    read_info.boxplot(column='read_length',by=['order'],ax=ax)\n",
    "    ax.set_ylim(0,30000)\n",
    "    ax.set_ylabel(\"Length\")\n",
    "    ax.set_xlabel(\"Order\")\n",
    "    plt.title('')\n",
    "    plt.suptitle('') \n",
    "    lenorderbox_outpath = PurePath(outdir,f'{prefix}_Read_length_order_distribution.png')\n",
    "    plt.savefig(lenorderbox_outpath,format = 'png',dpi=300,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T09:50:01.997147Z",
     "start_time": "2021-08-16T09:49:07.637324Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from pathlib import PurePath\n",
    "import seaborn as sns\n",
    "porec_dir = '/public/home/lizw/task/pore_c/porec_1000_filter_mainchr_result'\n",
    "prefix = 'DpnII_run04'\n",
    "mpq=1\n",
    "order=2\n",
    "align_dir = Path(PurePath(porec_dir,'align_table'))\n",
    "align_dir_porec_generator = align_dir.glob(prefix + \"*pore_c.parquet\")\n",
    "align_batch_porec_merge_df = pyarrow.concat_tables(list(map(pq.read_table,align_dir_porec_generator))).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T09:52:30.106527Z",
     "start_time": "2021-08-16T09:52:29.582155Z"
    }
   },
   "outputs": [],
   "source": [
    "def divide_order(x):\n",
    "    if x <= 3:\n",
    "        return str(x)\n",
    "    elif (x == 4) or (x == 5):\n",
    "        return '4-5'\n",
    "    elif 6<=x<=10:\n",
    "        return '6-10'\n",
    "    elif 11<=x<=20:\n",
    "        return '11-20'\n",
    "    elif x > 20:\n",
    "        return '20+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T09:54:30.670994Z",
     "start_time": "2021-08-16T09:53:09.865454Z"
    }
   },
   "outputs": [],
   "source": [
    "align_batch_porec_merge_df_pass = align_batch_porec_merge_df.query('pass_filter==True').query('mapping_quality>=@mpq')\n",
    "align_batch_porec_merge_df_singleton = align_batch_porec_merge_df.query(\"filter_reason=='singleton'\").query('mapping_quality>=@mpq')\n",
    "align_allorder = pd.concat([align_batch_porec_merge_df_pass,align_batch_porec_merge_df_singleton],axis=0)\n",
    "outdir = '/public/home/lizw/task/pore_c/tools/jp_note/new'\n",
    "\n",
    "#Importmant fixation in V2.1\n",
    "#According to PoreC : We refer to the set of filtered alignments associated with a given Pore-C read as a (multi-way) contact, and the number of fragments associated with a contact as its order.\n",
    "#When multiple alignment in the same read align to the same fragment, it would count multiple times when calculating order\n",
    "#Example fragmeng_id in read1 listed like this: 1,2,3,2,2,3,0   the order is 7 rather than just counting the fragment types. \n",
    "align_allorder['order'] = align_allorder.groupby(\"read_name\")['fragment_id'].transform('count')\n",
    "#use the mid point as final position: ref: ~/software/Pore-C-Snakemake_10Feb/.snakemake/conda/c2039cdc/lib/python3.8/site-packages/pore_c/analyses/contacts.py\n",
    "\n",
    "align_allorder = align_allorder.assign(\n",
    "    fragment_mid = lambda x: np.rint((x.fragment_start + x.fragment_end)*0.5)\n",
    "    .astype(int)\n",
    "    )\n",
    "order_count = align_allorder['order']\n",
    "#align_allorder['fragment_mid'] =  align_allorder.eval('fragment_end+fragment_start+1')//2\n",
    "#modified according to porec_tools\n",
    "\n",
    "read_info =  align_allorder.reindex(columns=['read_name','read_length','order']).drop_duplicates()\n",
    "list_sorted = ['1','2','3','4-5','6-10','11-20','>20']\n",
    "read_info['divide_order'] = read_info['order'].apply(divide_order).astype('category').cat.set_categories(list_sorted) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T09:18:51.808740Z",
     "start_time": "2021-08-06T09:17:57.298749Z"
    }
   },
   "outputs": [],
   "source": [
    "readID_order_map = read_info.groupby('divide_order')['read_name']\n",
    "pair_dir = Path(PurePath(porec_dir,'pairs'))\n",
    "pair_file = str(list(pair_dir.glob(prefix + \"*.sorted.pairs.gz\"))[0])\n",
    "\n",
    "pair_table = pd.read_table(\n",
    "    pair_file,                     \n",
    "    comment=\"#\",             \n",
    "    compression='gzip',\n",
    "    names=['readID','chr1','pos1','chr2','pos2','strand1','strand2','pair_type','align1_idx','align2_idx','distance_on_read']\n",
    ")\n",
    "\n",
    "pair_table.replace({'readID': {'read|_[0-9]+': ''}},regex=True,inplace=True)\n",
    "import pypairix\n",
    "pair_comment = pypairix.open(pair_file).get_header()\n",
    "\n",
    "for a,b in readID_order_map:\n",
    "    pair_slice = pair_table.query('readID in @b')\n",
    "    pair_order_path = PurePath(outdir,f'{prefix}.order_{a}.pair')\n",
    "    with open(pair_order_path,'w+') as pair_out:\n",
    "        pair_out.write('\\n'.join(pair_comment))\n",
    "    pair_slice.to_csv(pair_order_path,header=None,index=None,mode='a',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairix",
   "language": "python",
   "name": "pairix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
